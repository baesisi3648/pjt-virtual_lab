"""Pinecone Vector Database Client"""
from pinecone.grpc import PineconeGRPC as Pinecone
from openai import OpenAI
from config import settings
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


class PineconeRAGClient:
    """Pinecone ê¸°ë°˜ RAG ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        # Pinecone ì´ˆê¸°í™” (gRPC)
        self.pc = Pinecone(api_key=settings.PINECONE_API_KEY)
        self.index = self.pc.Index(settings.PINECONE_INDEX_NAME)

        # OpenAI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸
        self.openai = OpenAI(api_key=settings.OPENAI_API_KEY)

        logger.info(f"âœ… Pinecone ì—°ê²°: {settings.PINECONE_INDEX_NAME}")

    def embed_text(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        response = self.openai.embeddings.create(
            model=settings.EMBEDDING_MODEL,
            input=text
        )
        return response.data[0].embedding

    def upsert_documents(self, documents: List[Dict]):
        """ë¬¸ì„œ ì¶”ê°€ (PDF ì²­í¬)

        Args:
            documents: [{"text": "...", "source": "file.pdf", "page": 1}, ...]
        """
        vectors = []
        for i, doc in enumerate(documents):
            vector_id = f"{doc.get('source', 'doc')}_{doc.get('page', 0)}_{i}"
            embedding = self.embed_text(doc["text"])

            vectors.append({
                "id": vector_id,
                "values": embedding,
                "metadata": {
                    "text": doc["text"],
                    "source": doc.get("source", "unknown"),
                    "page": doc.get("page", 0)
                }
            })

        # Batch upsert (100ê°œì”©)
        batch_size = 100
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i + batch_size]
            self.index.upsert(vectors=batch)
            logger.info(f"ğŸ“¤ ì—…ë¡œë“œ: {i+len(batch)}/{len(vectors)}")

        logger.info(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")

    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """ì¿¼ë¦¬ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

        Returns:
            [{"text": "...", "source": "...", "page": 1, "score": 0.95}, ...]
        """
        # ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_embedding = self.embed_text(query)

        # Pinecone ê²€ìƒ‰
        results = self.index.query(
            vector=query_embedding,
            top_k=top_k,
            include_metadata=True
        )

        # ê²°ê³¼ í¬ë§·íŒ…
        documents = []
        for match in results["matches"]:
            documents.append({
                "text": match["metadata"]["text"],
                "source": match["metadata"]["source"],
                "page": match["metadata"].get("page", 0),
                "score": match["score"]
            })

        logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        return documents


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_pinecone_client = None


def get_pinecone_client() -> PineconeRAGClient:
    """Pinecone í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤"""
    global _pinecone_client
    if _pinecone_client is None:
        _pinecone_client = PineconeRAGClient()
    return _pinecone_client
