# Virtual Lab Final - TASKS.md

> **í”„ë¡œì íŠ¸**: Virtual Lab for NGT Safety Framework (Production)
> **ëª©í‘œ**: MVP â†’ Production ì—…ê·¸ë ˆì´ë“œ (Dynamic Team + Autonomous Research + Parallel Meetings)
> **ìƒì„±ì¼**: 2026-02-08

---

## ğŸ“Š Phase Overview

| Phase | ì œëª© | í•µì‹¬ ëª©í‘œ | íƒœìŠ¤í¬ ìˆ˜ |
|-------|------|-----------|----------|
| **P0** | Project Setup | PostgreSQL + ChromaDB + Redis í™˜ê²½ êµ¬ì¶• | 5 |
| **P1** | Knowledge Injection | RAG ì‹œìŠ¤í…œ êµ¬ì¶• (ë²¡í„° DB + ê·œì œ ë¬¸ì„œ) | 4 |
| **P2** | Eyes & Ears | Web Search ì—°ë™ (Tavily API) | 4 |
| **P3** | The Brain | ë³‘ë ¬ íšŒì˜ + ë™ì  íŒ€ êµ¬ì„± | 6 |
| **P4** | The Face | Next.js UI + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° | 5 |

**Total**: 24 Tasks

---

## Phase 0: Project Setup

### P0-T1: Database Infrastructure Setup
**ëª©í‘œ**: PostgreSQL + ChromaDB ì»¨í…Œì´ë„ˆ í™˜ê²½ êµ¬ì¶•

**ì‘ì—…**:
- [ ] `docker-compose.yml` ì‘ì„±
  - PostgreSQL (ì„¸ì…˜ ì´ë ¥ ì €ì¥)
  - ChromaDB (ë²¡í„° ì €ì¥ì†Œ)
  - Redis (Celery ë°±ì—”ë“œ)
- [ ] `init.sql` ì‘ì„± (sessions, reports í…Œì´ë¸”)
- [ ] í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

**ê²€ì¦**:
```bash
docker-compose up -d
docker-compose ps  # 3ê°œ ì»¨í…Œì´ë„ˆ ëª¨ë‘ healthy
```

**ì°¨ë‹¨**: ì—†ìŒ

---

### P0-T2: Backend Dependencies Update
**ëª©í‘œ**: Production ì˜ì¡´ì„± ì¶”ê°€

**ì‘ì—…**:
- [ ] `requirements.txt` ì—…ë°ì´íŠ¸
  ```
  chromadb>=0.4.0
  psycopg2-binary>=2.9.0
  sqlalchemy>=2.0.0
  celery>=5.3.0
  redis>=5.0.0
  tavily-python>=0.3.0
  langsmith>=0.1.0
  ```
- [ ] ê°€ìƒí™˜ê²½ ì¬ìƒì„± í…ŒìŠ¤íŠ¸

**ê²€ì¦**:
```bash
pip install -r requirements.txt
python -c "import chromadb; import tavily"
```

**ì°¨ë‹¨**: ì—†ìŒ

---

### P0-T3: Environment Configuration
**ëª©í‘œ**: í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ ê°•í™”

**ì‘ì—…**:
- [ ] `.env.example` ì—…ë°ì´íŠ¸
  ```
  POSTGRES_URL=postgresql://...
  CHROMA_HOST=localhost
  CHROMA_PORT=8001
  TAVILY_API_KEY=tvly-...
  LANGSMITH_API_KEY=lsv2_...
  REDIS_URL=redis://localhost:6379
  ```
- [ ] `config.py` ì‘ì„± (Pydantic Settings)
- [ ] Secrets ê²€ì¦ ë¡œì§ ì¶”ê°€

**ê²€ì¦**:
```python
from config import settings
assert settings.TAVILY_API_KEY.startswith("tvly-")
```

**ì°¨ë‹¨**: ì—†ìŒ

---

### P0-T4: Database Models
**ëª©í‘œ**: SQLAlchemy ORM ëª¨ë¸ ì •ì˜

**ì‘ì—…**:
- [ ] `models/session.py` ì‘ì„±
  ```python
  class Session(Base):
      id: UUID
      user_query: Text
      final_report: Text
      created_at: DateTime
  ```
- [ ] `models/agent_log.py` ì‘ì„± (ì—ì´ì „íŠ¸ í–‰ë™ ì¶”ì )
- [ ] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™”

**ê²€ì¦**:
```bash
alembic revision --autogenerate -m "init"
alembic upgrade head
```

**ì°¨ë‹¨**: P0-T1 (DB ì‹¤í–‰ í•„ìš”)

---

### P0-T5: Celery Task Queue Setup
**ëª©í‘œ**: ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ ì¸í”„ë¼

**ì‘ì—…**:
- [ ] `celery_app.py` ì‘ì„±
  ```python
  app = Celery('virtual_lab', broker='redis://...')
  ```
- [ ] `tasks/research_task.py` ì‘ì„± (ì¥ì‹œê°„ ì—°êµ¬ ì‘ì—…)
- [ ] Celery worker ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

**ê²€ì¦**:
```bash
celery -A celery_app worker --loglevel=info
# í…ŒìŠ¤íŠ¸ íƒœìŠ¤í¬ submit
```

**ì°¨ë‹¨**: P0-T1 (Redis í•„ìš”)

---

## Phase 1: Knowledge Injection (RAG System)

### P1-T1: ChromaDB Collection Setup
**ëª©í‘œ**: ê·œì œ ë¬¸ì„œìš© ë²¡í„° ì»¬ë ‰ì…˜ ìƒì„±

**ì‘ì—…**:
- [ ] `rag/chroma_client.py` ì‘ì„±
  ```python
  client = chromadb.HttpClient(host=CHROMA_HOST)
  collection = client.get_or_create_collection("regulatory_docs")
  ```
- [ ] Embedding ëª¨ë¸ ì„ íƒ (OpenAI text-embedding-3-small)
- [ ] ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜

**ê²€ì¦**:
```python
collection.count()  # 0 (ì´ˆê¸° ìƒíƒœ)
```

**ì°¨ë‹¨**: P0-T1 (ChromaDB ì‹¤í–‰ í•„ìš”)

---

### P1-T2: PDF Processing Pipeline
**ëª©í‘œ**: PDF â†’ ì²­í¬ â†’ ì„ë² ë”© â†’ ì €ì¥

**ì‘ì—…**:
- [ ] `rag/pdf_processor.py` ì‘ì„±
  - PyPDF2ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  - RecursiveCharacterTextSplitter (chunk_size=1000)
- [ ] `data/regulatory/` í´ë”ì— ìƒ˜í”Œ PDF ì¤€ë¹„
- [ ] ë°°ì¹˜ ì„ë² ë”© í•¨ìˆ˜ ì‘ì„±

**ê²€ì¦**:
```bash
python rag/pdf_processor.py --file data/regulatory/codex_guideline.pdf
# ChromaDBì— 500ê°œ ì²­í¬ ì €ì¥ í™•ì¸
```

**ì°¨ë‹¨**: P1-T1

---

### P1-T3: RAG Retrieval Function
**ëª©í‘œ**: ì¿¼ë¦¬ â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

**ì‘ì—…**:
- [ ] `rag/retriever.py` ì‘ì„±
  ```python
  def retrieve(query: str, top_k=5) -> List[Document]:
      results = collection.query(query_texts=[query], n_results=top_k)
      return results
  ```
- [ ] Reranking ë¡œì§ ì¶”ê°€ (ì˜µì…˜)
- [ ] Citation í¬ë§·íŒ… í•¨ìˆ˜

**ê²€ì¦**:
```python
docs = retrieve("What is substantial equivalence?")
assert len(docs) == 5
assert "Codex" in docs[0].metadata['source']
```

**ì°¨ë‹¨**: P1-T2

---

### P1-T4: Agent RAG Integration
**ëª©í‘œ**: Scientist ì—ì´ì „íŠ¸ì— RAG Tool ì¶”ê°€

**ì‘ì—…**:
- [ ] `agents/scientist.py` ìˆ˜ì •
  ```python
  tools = [rag_search_tool]  # LangChain Toolë¡œ ë˜í•‘
  ```
- [ ] System Prompt ì—…ë°ì´íŠ¸
  - "ê´€ë ¨ ê·œì œë¥¼ ë¨¼ì € ê²€ìƒ‰í•˜ì„¸ìš”"
- [ ] RAG íˆíŠ¸ ì—¬ë¶€ ë¡œê¹…

**ê²€ì¦**:
```python
response = scientist.invoke("ëŒ€ë‘ ì•Œë ˆë¥´ê¸° í‰ê°€ ë°©ë²•ì€?")
assert "[ì¶œì²˜: Codex Guideline]" in response
```

**ì°¨ë‹¨**: P1-T3

---

## Phase 2: Eyes & Ears (Web Search)

### P2-T1: Tavily API Client
**ëª©í‘œ**: Tavily ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

**ì‘ì—…**:
- [ ] `search/tavily_client.py` ì‘ì„±
  ```python
  from tavily import TavilyClient
  client = TavilyClient(api_key=TAVILY_API_KEY)
  ```
- [ ] Domain í•„í„°ë§ ì„¤ì •
  - include_domains: [".gov", "nature.com", "sciencedirect.com"]
- [ ] Rate limiting ì²˜ë¦¬

**ê²€ì¦**:
```python
results = client.search("CRISPR off-target effects 2025")
assert len(results['results']) > 0
```

**ì°¨ë‹¨**: P0-T3 (API Key í•„ìš”)

---

### P2-T2: Search Tool for Agents
**ëª©í‘œ**: LangChain Toolë¡œ ë˜í•‘

**ì‘ì—…**:
- [ ] `tools/web_search.py` ì‘ì„±
  ```python
  @tool
  def web_search(query: str) -> str:
      """ìµœì‹  ë…¼ë¬¸ ë° ê·œì œ ë™í–¥ ê²€ìƒ‰"""
      results = tavily_client.search(query)
      return format_results(results)
  ```
- [ ] Citation Rule ê°•ì œ (ì¶œì²˜ URL í¬í•¨)
- [ ] ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (Redis)

**ê²€ì¦**:
```python
result = web_search.invoke("Calyxt high oleic soybean FDA approval")
assert "calyxt.com" in result or "fda.gov" in result
```

**ì°¨ë‹¨**: P2-T1

---

### P2-T3: Agent Search Integration
**ëª©í‘œ**: ëª¨ë“  ì—ì´ì „íŠ¸ì— ê²€ìƒ‰ ê¶Œí•œ ë¶€ì—¬

**ì‘ì—…**:
- [ ] `agents/pi.py` - tools ì—…ë°ì´íŠ¸
- [ ] `agents/scientist.py` - tools ì—…ë°ì´íŠ¸
- [ ] `agents/critic.py` - tools ì—…ë°ì´íŠ¸
- [ ] System Prompt ìˆ˜ì •
  - "ìµœì‹  ì •ë³´ê°€ í•„ìš”í•˜ë©´ web_searchë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"

**ê²€ì¦**:
```python
response = pi.invoke("2025ë…„ EU NGT ë²•ì•ˆ í†µê³¼ ì—¬ë¶€")
# ì‹¤ì œ ì›¹ ê²€ìƒ‰ í›„ ë‹µë³€ í™•ì¸
```

**ì°¨ë‹¨**: P2-T2

---

### P2-T4: Search Observability
**ëª©í‘œ**: ê²€ìƒ‰ í–‰ìœ„ ì¶”ì  (LangSmith)

**ì‘ì—…**:
- [ ] LangSmith íŠ¸ë ˆì´ì‹± í™œì„±í™”
  ```python
  from langsmith import trace
  @trace
  def web_search(...):
  ```
- [ ] ê²€ìƒ‰ ì¿¼ë¦¬ ë¡œê¹… (DB ì €ì¥)
- [ ] ëŒ€ì‹œë³´ë“œ í™•ì¸ ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦

**ê²€ì¦**:
```
LangSmith UIì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¸
```

**ì°¨ë‹¨**: P2-T3

---

## Phase 3: The Brain (Parallel & Dynamic)

### P3-T1: Parallel Meeting Architecture
**ëª©í‘œ**: LangGraph Map-Reduce íŒ¨í„´ êµ¬í˜„

**ì‘ì—…**:
- [ ] `workflow/parallel_graph.py` ì‘ì„±
  ```python
  def parallel_risk_analysis(state):
      # 3ê°œ ì—ì´ì „íŠ¸ê°€ ë™ì‹œì— ìœ„í—˜ ë¶„ì„
      futures = [agent_a.ainvoke(), agent_b.ainvoke(), agent_c.ainvoke()]
      results = await asyncio.gather(*futures)
      return {"parallel_views": results}
  ```
- [ ] Merge ë¡œì§ êµ¬í˜„ (PIê°€ í†µí•©)
- [ ] ë…¸ë“œ ê°„ ì˜ì¡´ì„± ì •ì˜

**ê²€ì¦**:
```python
result = await parallel_graph.ainvoke({"query": "ëŒ€ë‘ ìœ„í—˜ ìš”ì†Œ"})
assert len(result['parallel_views']) == 3
```

**ì°¨ë‹¨**: ì—†ìŒ (ê¸°ì¡´ graph.py ë¦¬íŒ©í† ë§)

---

### P3-T2: Dynamic Agent Factory
**ëª©í‘œ**: PIê°€ ì „ë¬¸ê°€ í”„ë¡œí•„ ìƒì„±

**ì‘ì—…**:
- [ ] `agents/factory.py` ì‘ì„±
  ```python
  def create_specialist(profile: dict) -> Agent:
      """
      profile = {
          "role": "Plant Metabolomics Expert",
          "focus": "fatty acid composition",
          "tools": ["rag_search", "web_search"]
      }
      """
      system_prompt = generate_prompt(profile)
      return Agent(llm=llm, system=system_prompt, tools=tools)
  ```
- [ ] í”„ë¡œí•„ í…œí”Œë¦¿ ì •ì˜

**ê²€ì¦**:
```python
expert = create_specialist({"role": "Allergy Specialist"})
response = expert.invoke("ëŒ€ë‘ P34 ë‹¨ë°±ì§ˆ ë¶„ì„")
# ì „ë¬¸ì ì¸ ë‹µë³€ í™•ì¸
```

**ì°¨ë‹¨**: ì—†ìŒ

---

### P3-T3: PI Decision Logic
**ëª©í‘œ**: PIê°€ ì¿¼ë¦¬ ë¶„ì„ í›„ íŒ€ êµ¬ì„± ê²°ì •

**ì‘ì—…**:
- [ ] `agents/pi.py` ìˆ˜ì •
  ```python
  def decide_team(user_query: str) -> List[dict]:
      """
      LLMì—ê²Œ "ì´ ì¿¼ë¦¬ì— í•„ìš”í•œ ì „ë¬¸ê°€ëŠ”?"ì´ë¼ê³  ë¬¼ì–´ë´„
      return [
          {"role": "Metabolomics Expert", "focus": "lipid analysis"},
          {"role": "Nutrition Toxicologist", ...}
      ]
      """
  ```
- [ ] ê¸°ë³¸ íŒ€ vs ë™ì  íŒ€ ë¶„ê¸° ë¡œì§

**ê²€ì¦**:
```python
team = decide_team("ê³ ì˜¬ë ˆì‚° ëŒ€ë‘ ì•ˆì „ì„± í‰ê°€")
assert any("Metabol" in expert['role'] for expert in team)
```

**ì°¨ë‹¨**: P3-T2

---

### P3-T4: Dynamic Workflow Execution
**ëª©í‘œ**: ê²°ì •ëœ íŒ€ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

**ì‘ì—…**:
- [ ] `workflow/dynamic_graph.py` ì‘ì„±
  ```python
  def build_graph(team_profiles: List[dict]):
      # íŒ€ êµ¬ì„±ì— ë§ì¶° ê·¸ë˜í”„ ë™ì  ìƒì„±
      specialists = [create_specialist(p) for p in team_profiles]
      graph.add_node("parallel_meeting", parallel_func(specialists))
      return graph.compile()
  ```
- [ ] ê¸°ì¡´ graph.pyì™€ í†µí•©

**ê²€ì¦**:
```python
graph = build_graph([...])
result = await graph.ainvoke({"query": "..."})
```

**ì°¨ë‹¨**: P3-T3

---

### P3-T5: Critic Merge Logic
**ëª©í‘œ**: ë³‘ë ¬ ì˜ê²¬ í†µí•© ê°•í™”

**ì‘ì—…**:
- [ ] `agents/critic.py` ìˆ˜ì •
  ```python
  def merge_views(views: List[str]) -> str:
      """
      - ì¤‘ë³µ ì œê±°
      - ê°€ì¥ ë³´ìˆ˜ì  ì•ˆì „ ê¸°ì¤€ ì„ íƒ
      - ê·¼ê±° ë¶€ì¡±í•œ ì˜ê²¬ ê¸°ê°
      """
  ```
- [ ] Conflict Resolution ê·œì¹™ ì •ì˜

**ê²€ì¦**:
```python
merged = critic.merge_views([view_a, view_b, view_c])
assert "ë™ë¬¼ ì‹¤í—˜ ë¶ˆí•„ìš”" in merged  # í•©ë¦¬ì  í•©ì˜
```

**ì°¨ë‹¨**: P3-T1

---

### P3-T6: End-to-End Parallel Test
**ëª©í‘œ**: ì „ì²´ Brain ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

**ì‘ì—…**:
- [ ] `tests/test_parallel_brain.py` ì‘ì„±
  - ì¿¼ë¦¬: "ê³ ì˜¬ë ˆì‚° ëŒ€ë‘ ì•ˆì „ì„± í‰ê°€"
  - ì˜ˆìƒ: ëŒ€ì‚¬ì²´í•™ì + ì˜ì–‘í•™ì ìƒì„±
  - ë³‘ë ¬ íšŒì˜ ì‹¤í–‰
  - ìµœì¢… í†µí•© ë³´ê³ ì„œ ìƒì„±
- [ ] 5ë¶„ ì´ë‚´ ì‹¤í–‰ ì‹œê°„ ê²€ì¦

**ê²€ì¦**:
```bash
pytest tests/test_parallel_brain.py -v
```

**ì°¨ë‹¨**: P3-T4, P3-T5

---

## Phase 4: The Face (Next.js UI)

### P4-T1: Next.js Project Setup
**ëª©í‘œ**: React í”„ë¡ íŠ¸ì—”ë“œ ì´ˆê¸°í™”

**ì‘ì—…**:
- [ ] `frontend/` í´ë” ìƒì„±
  ```bash
  npx create-next-app@latest frontend --typescript --tailwind
  ```
- [ ] FastAPI CORS ì„¤ì •
- [ ] Proxy ì„¤ì • (Next.js â†’ FastAPI)

**ê²€ì¦**:
```bash
cd frontend && npm run dev
# http://localhost:3000 ì ‘ì† í™•ì¸
```

**ì°¨ë‹¨**: ì—†ìŒ

---

### P4-T2: Live Process Timeline
**ëª©í‘œ**: ì—ì´ì „íŠ¸ ìƒíƒœ ì‹¤ì‹œê°„ ì‹œê°í™”

**ì‘ì—…**:
- [ ] `components/ProcessTimeline.tsx` ì‘ì„±
  - Server-Sent Events (SSE) êµ¬ë…
  - íƒ€ì„ë¼ì¸ UI (Tailwind)
    - "ğŸ” ê²€ìƒ‰ ì¤‘..."
    - "ğŸ§  íšŒì˜ ì¤‘..."
    - "âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ"
- [ ] FastAPI SSE ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

**ê²€ì¦**:
```tsx
// ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ í™•ì¸
[12:01] PI: íŒ€ êµ¬ì„± ì¤‘...
[12:02] ëŒ€ì‚¬ì²´í•™ì: ì›¹ ê²€ìƒ‰ ì¤‘...
[12:03] ë³‘ë ¬ íšŒì˜ ì‹œì‘...
```

**ì°¨ë‹¨**: P4-T1

---

### P4-T3: Interactive Report Editor
**ëª©í‘œ**: ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìˆ˜ì • ê°€ëŠ¥

**ì‘ì—…**:
- [ ] `components/ReportEditor.tsx` ì‘ì„±
  - React Markdown ë Œë”ë§
  - ì¸ë¼ì¸ ìˆ˜ì • ëª¨ë“œ
  - "ì¬ê²€í†  ìš”ì²­" ë²„íŠ¼ (íŠ¹ì • ì„¹ì…˜)
- [ ] FastAPI ì¬ê²€í†  API ì¶”ê°€
  ```python
  POST /api/report/regenerate
  {"section": "ìœ„í—˜ ì‹ë³„", "feedback": "ì•Œë ˆë¥´ê¸° ë” ìì„¸íˆ"}
  ```

**ê²€ì¦**:
```
ì‚¬ìš©ìê°€ "ì•Œë ˆë¥´ê¸°" ì„¹ì…˜ í´ë¦­ â†’ ì¬ê²€í†  ìš”ì²­ â†’ ì—…ë°ì´íŠ¸ëœ ë‚´ìš© ë°˜ì˜
```

**ì°¨ë‹¨**: P4-T1

---

### P4-T4: FastAPI Streaming Response
**ëª©í‘œ**: ë³´ê³ ì„œ ìƒì„± ì¤‘ ì ì§„ì  ì¶œë ¥

**ì‘ì—…**:
- [ ] `server.py` ìˆ˜ì •
  ```python
  @app.post("/api/research/stream")
  async def stream_research():
      async def event_generator():
          async for chunk in graph.astream(...):
              yield f"data: {json.dumps(chunk)}\n\n"
      return StreamingResponse(event_generator())
  ```
- [ ] Frontendì—ì„œ ì²­í¬ ìˆ˜ì‹  ì²˜ë¦¬

**ê²€ì¦**:
```
ë³´ê³ ì„œê°€ ë¬¸ë‹¨ë³„ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ë‚˜íƒ€ë‚¨
```

**ì°¨ë‹¨**: P4-T2

---

### P4-T5: Production Deployment
**ëª©í‘œ**: Docker Compose ì „ì²´ ìŠ¤íƒ ë°°í¬

**ì‘ì—…**:
- [ ] `docker-compose.prod.yml` ì‘ì„±
  - frontend (Next.js build)
  - backend (FastAPI)
  - postgres, chromadb, redis
- [ ] Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„¤ì •
- [ ] í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

**ê²€ì¦**:
```bash
docker-compose -f docker-compose.prod.yml up -d
curl http://localhost/api/health  # 200 OK
curl http://localhost  # Next.js í™”ë©´ ë¡œë“œ
```

**ì°¨ë‹¨**: P4-T4

---

## ğŸ¯ ì‹¤í–‰ ê°€ì´ë“œ

### 1. ìˆœì°¨ ì‹¤í–‰ (ê¶Œì¥)
```bash
# Phase 0 ì™„ë£Œ í›„ Phase 1, ìˆœì°¨ ì§„í–‰
```

### 2. ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥ êµ¬ê°„
- P1-T1, P1-T2 (ë™ì‹œ ì‘ì—… ê°€ëŠ¥)
- P2-T1, P2-T2 (ë™ì‹œ ì‘ì—… ê°€ëŠ¥)
- P4-T1, P4-T2 (ë™ì‹œ ì‘ì—… ê°€ëŠ¥)

### 3. í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤
```
P0-T1 â†’ P1-T1 â†’ P1-T2 â†’ P1-T3 â†’ P1-T4
                                 â†“
P2-T1 â†’ P2-T2 â†’ P2-T3 â†’ P3-T1 â†’ P3-T6
                                 â†“
P4-T1 â†’ P4-T2 â†’ P4-T4 â†’ P4-T5
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [MVP README](./README.md)
- [virtual_lab_final.md](./virtual_lab_final.md) - ìƒì„¸ ê¸°íš
- [virtual_lab_script.md](./virtual_lab_script.md) - ì‹œë‚˜ë¦¬ì˜¤

---

**ìƒì„± ë„êµ¬**: tasks-generator v2.0
**ìƒì„± ì‹œê°**: 2026-02-08 12:45 KST
